{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns',None)\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier ,RandomForestClassifier ,GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import Ridge,Lasso\n",
    "from sklearn.metrics import roc_auc_score ,mean_squared_error,accuracy_score,classification_report,roc_curve,confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy.stats.mstats import winsorize\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"a2.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem statement:\n",
    "The problem statement revolves around the need to predict the forest cover type (the predominant kind of tree cover) from strictly cartographic variables (as opposed to remotely sensed data).\n",
    "\n",
    "It includes four wilderness areas located in the Roosevelt National Forest of northern Colorado. These areas represent forests with minimal human-caused disturbances, so that existing forest cover types are more a result of ecological processes rather than forest management practices.\n",
    "\n",
    "The study area includes four wilderness areas located in the Roosevelt National Forest of northern Colorado. Each observation is a 30m x 30m patch. You are asked to predict an integer classification for the forest cover type. The seven types are:\n",
    "\n",
    "1 - Spruce/Fir\n",
    "2 - Lodgepole Pine\n",
    "3 - Ponderosa Pine\n",
    "4 - Cottonwood/Willow\n",
    "5 - Aspen\n",
    "6 - Douglas-fir\n",
    "7 - Krummholz\n",
    "\n",
    "### About the dataset\n",
    "A zipped file containing following items is given:\n",
    "\n",
    "train.csv\n",
    "The data file train.csv contains the 9072 instances with the 56 features including the target feature.\n",
    "\n",
    "test.csv\n",
    "The datafile test.csv contains the 6048instances with the 55 features excluding the target feature.\n",
    "\n",
    "sample_submission.csv\n",
    "Explained under the Submission sub-heading\n",
    "\n",
    "FCDataDictionary.csv\n",
    "The file contains data dictionary(Dictionary explaining what each feature of the dataset means) of the forest cover dataset\n",
    "\n",
    "forest_cover_student_template.ipynb\n",
    "A template notebook explaining the task breakdown to solve the given problem statement (Learners are recommended to use it)\n",
    "\n",
    "### Submission\n",
    "After training of the model on train.csv data, learner has to predict the target feature of the test.csv data using the trained model. The learner has to then submit a csv file with the predicted feature.\n",
    "\n",
    "Sample submission file(sample_submission.csv) is given to you as reference to the format expected when you submit\n",
    "\n",
    "Evaluation metrics\n",
    "For this particular dataset we are using accuracy_score as the evaluation metric.\n",
    "\n",
    "Submissions will be evaluated based on Accuracy score\n",
    "\n",
    "#### Outcomes\n",
    "The main objective of this task is to provide you with an open field where you can practise and work your way with a dataset end to end without any restrictions from our side. So feel free to try out different preprocessing and feature selection techniques and apply different models of your choice and tune them until you arrive at your best solution.\n",
    "\n",
    "### In this project, you will apply the following concepts:\n",
    "\n",
    "EDA & Data Preprocessing\n",
    "Feature Selection\n",
    "Model Building and hyperparameter tuning\n",
    "After completing this project, you will have a better understanding of how to how to work on a dataset end to end and the different strategies you can use to increase the evaluation metric.\n",
    "\n",
    "### Skills Covered:\n",
    "Hyperparmeter Tuning, \n",
    "Ensemble Methods, \n",
    "RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset\n",
    "\n",
    "- Load the train data and using all your knowledge of pandas try to explore the different statistical properties of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_true, y_pred, normalize=True, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6376</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8962</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7122</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>931</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3678</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  Cover_Type\n",
       "0  6376           5\n",
       "1  8962           7\n",
       "2  7122           5\n",
       "3   931           5\n",
       "4  3678           6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_sb():\n",
    "    df = pd.read_csv('sample_submission.csv')\n",
    "#     print(df.info())\n",
    "    return df\n",
    "\n",
    "df = load_sb()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Traincsv score: 1.00\n",
      "Train Accuracy:\n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "# Code starts here\n",
    "#Loading the Train data\n",
    "def load_train():\n",
    "    df = pd.read_csv('train.csv')\n",
    "#     print(df.info())\n",
    "    return df\n",
    "\n",
    "#Loading the Test data\n",
    "def load_test():\n",
    "    df = pd.read_csv('test.csv')\n",
    "#     print(df.info())\n",
    "    return df\n",
    "\n",
    "#Loading the sample_submission file\n",
    "def load_sb():\n",
    "    df = pd.read_csv('sample_submission.csv')\n",
    "#     print(df.info())\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "train = load_train()\n",
    "# train.head()\n",
    "test = load_test()\n",
    "# test.head()\n",
    "# Storing the Id column\n",
    "Id = test[['Id']]\n",
    "test.drop('Id',1,inplace=True)\n",
    "\n",
    "sb = load_sb()\n",
    "# sb.head()\n",
    "\n",
    "#Initial Random Forest Model fitting with 1000 estimators. Note below, that the labels lie in the last column, Cover Type. \n",
    "rf=RandomForestClassifier(n_estimators=1000, bootstrap=True, oob_score=True) \n",
    "rf.fit(df.ix[:,:-1].values, df.ix[:,-1:].values.ravel()) \n",
    "print(\"Initial Traincsv score: %.2f\" %rf.score(df.ix[:,:-1].values, df.ix[:,-1:].values.ravel()))\n",
    "\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=6)\n",
    "#Initial Random Forest Model fitting with 1000 estimators. Note below, that the labels lie in the last column, Cover Type. \n",
    "rf=RandomForestClassifier(n_estimators=1000, bootstrap=True, oob_score=True) \n",
    "rf.fit(df.ix[:,:-1].values, df.ix[:,-1:].values.ravel()) \n",
    "print(\"Initial Traincsv score: %.2f\" %rf.score(df.ix[:,:-1].values, df.ix[:,-1:].values.ravel()))\n",
    "print('Train Accuracy:\\n',rf.score(X_train,y_train))\n",
    "\n",
    "accuracy_score()\n",
    "# Code ends here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Traincsv score: 1.00\n"
     ]
    }
   ],
   "source": [
    "#Loading the Train data\n",
    "def load_train():\n",
    "    df = pd.read_csv('train.csv')\n",
    "#     print(df.info())\n",
    "    return df\n",
    "\n",
    "#Loading the Test data\n",
    "def load_test():\n",
    "    df = pd.read_csv('test.csv')\n",
    "#     print(df.info())\n",
    "    return df\n",
    "\n",
    "# #Loading the sample_submission file\n",
    "# def load_sb():\n",
    "#     df = pd.read_csv('sample_submission.csv')\n",
    "# #     print(df.info())\n",
    "#     return df\n",
    "\n",
    "\n",
    "\n",
    "train = load_train()\n",
    "# train.head()\n",
    "test = load_test()\n",
    "# test.head()\n",
    "# Storing the Id column\n",
    "Id = test[['Id']]\n",
    "test.drop('Id',1,inplace=True)\n",
    "\n",
    "# sb = load_sb()\n",
    "# sb.head()\n",
    "#removing ID column\n",
    "train.drop(columns=['Id'],axis=1,inplace=True)\n",
    "# train.head()\n",
    "\n",
    "def rff(df):\n",
    "    global rf\n",
    "    #Initial Random Forest Model fitting with 1000 estimators. Note below, that the labels lie in the last column, Cover Type. \n",
    "    rf=RandomForestClassifier(n_estimators=1000, bootstrap=True, oob_score=True) \n",
    "    rf.fit(df.ix[:,:-1].values, df.ix[:,-1:].values.ravel()) \n",
    "    print(\"Initial Traincsv score: %.2f\" %rf.score(df.ix[:,:-1].values, df.ix[:,-1:].values.ravel()))\n",
    "\n",
    "    \n",
    "\n",
    "rff(train)\n",
    "\n",
    "\n",
    "\n",
    "# Preprocessed Test File\n",
    "y_pred = rf.predict(test)\n",
    "# print('Accuracy: ',accuracy_score(y_pred,))\n",
    "\n",
    "#predicting on test file\n",
    "y_pred = pd.DataFrame(y_pred,columns=['Cover_Type']) \n",
    "\n",
    "submission = pd.concat([Id,y_pred['Cover_Type']],1)\n",
    "submission.to_csv('sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA & Data Preprocessing\n",
    "\n",
    "- The target is the only categorical feature consisting of 7 classes and all the other features are continuous. \n",
    "- Check out the best plots for plotting between categorical target and continuous features and try making some inferences from these plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Code starts here\n",
    "\n",
    "\n",
    "\n",
    "train.ix[:,:10].hist(figsize=(16,10), bins=50) \n",
    "plt.show() \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection and Model building\n",
    "\n",
    "- Separate the features and target and then split the train data into train and validation set.\n",
    "- Apply different models of your choice and  then predict on the validation data and find the `accuracy_score` for this prediction.\n",
    "- Try improving upon the `accuracy_score` using different feature selection techniques like wrapper methods, PCA and try using hyperparameter tuning to find the parameters that give the best accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Starts here\n",
    "\n",
    "\n",
    "#Always call fit on the estimator before invoking this method. \n",
    "def importances(estimator, col_array, title):\n",
    "    # Calculate the feature ranking - Top 10 \n",
    "    importances = estimator.feature_importances_ \n",
    "    indices = np.argsort(importances)[::-1] \n",
    "    print (\"%s Top 20 Important Features\\n\" %title)\n",
    "    for f in range(20): \n",
    "        print(\"%d. %s (%f)\" % (f + 1, col_array.columns[indices[f]], importances[indices[f]])) \n",
    "        #Mean Feature Importance \n",
    "    print(\"\\nMean Feature Importance %.6f\" %np.mean(importances))\n",
    "    #Plot the feature importances of the forest \n",
    "    indices=indices[:10] \n",
    "    plt.figure() \n",
    "    plt.title(title+\" Top 10 Feature importances\") \n",
    "    plt.bar(range(10), importances[indices], \n",
    "                color=\"gr\", align=\"center\") \n",
    "    plt.xticks(range(10), col_array.columns[indices], fontsize=14, rotation=90) \n",
    "    plt.xlim([-1, 10]) \n",
    "    plt.show() \n",
    "        \n",
    "#Call the method we just created to display the feature importances \n",
    "importances(rf, train, \"Cover Type (Initial RF)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on the test data and creating the sample submission file.\n",
    "\n",
    "- Load the test data and store the `Id` column in a separate variable.\n",
    "- Perform the same operations on the test data that you have performed on the train data.\n",
    "- Create the submission file as a `csv` file consisting of the `Id` column from the test data and your prediction as the second column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code starts here\n",
    "#Loading the Train data\n",
    "def load_train():\n",
    "    df = pd.read_csv('train.csv')\n",
    "#     print(df.info())\n",
    "    return df\n",
    "\n",
    "#Loading the Test data\n",
    "def load_test():\n",
    "    df = pd.read_csv('test.csv')\n",
    "#     print(df.info())\n",
    "    return df\n",
    "\n",
    "#Loading the sample_submission file\n",
    "def load_sb():\n",
    "    df = pd.read_csv('sample_submission.csv')\n",
    "#     print(df.info())\n",
    "    return df\n",
    "\n",
    "train = load_train()\n",
    "# train.head()\n",
    "test = load_test()\n",
    "# test.head()\n",
    "sb = load_sb()\n",
    "# sb.head()\n",
    "\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=6)\n",
    "#Initial Random Forest Model fitting with 1000 estimators. Note below, that the labels lie in the last column, Cover Type. \n",
    "rf=RandomForestClassifier(n_estimators=1000, bootstrap=True, oob_score=True) \n",
    "rf.fit(df.ix[:,:-1].values, df.ix[:,-1:].values.ravel()) \n",
    "print(\"Initial Traincsv score: %.2f\" %rf.score(df.ix[:,:-1].values, df.ix[:,-1:].values.ravel()))\n",
    "print('Train Accuracy:\\n',rf.score(X_train,y_train))\n",
    "\n",
    "\n",
    "# Code ends here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
